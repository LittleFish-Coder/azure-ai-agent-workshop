{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# AI Search02 - Agentic retrieval using Azure AI Search and Azure AI Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and an Azure AI Agent.\n",
    "\n",
    "In this walkthrough, you will:\n",
    "\n",
    "+ Create an \"earth_at_night\" search index\n",
    "+ Load it with documents from a GitHub URL\n",
    "+ Create a knowledge agent on Azure AI Search that points to an LLM for intelligent query planning\n",
    "+ Create a Foundry agent in Azure AI Foundry to determine when queries are needed\n",
    "+ Create a Azure AI Agent tool (client) to orchestrate all requests\n",
    "+ Start a chat with the agent\n",
    "\n",
    "This notebook is referenced in [Build an agentic retrieval pipeline in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "This exercise differs from the [Agentic Retrieval Quickstart](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval) in how it uses Azure AI Agent to determine whether to retrieve data from the index, and how it uses an agent tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ Azure AI Search, basic tier or higher, in any region that supports semantic ranker.\n",
    "\n",
    "+ Azure OpenAI, and you should have an **Azure AI Developer** role assignment to create a Foundry project.\n",
    "\n",
    "+ An [Azure AI agent and Foundry project](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal), created in the Azure AI Foundry portal, with the basic setup, used for creating the Foundry agent.\n",
    "\n",
    "+ A deployment of a [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) in your Foundry project. This notebook uses gpt-4o-mini. We recommend 100,000 token capacity. You can find capacity and the rate limit in the model deployments list in the Azure AI Foundry portal.\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    " `.env` modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI\n",
    "+ Azure AI Foundry project\n",
    "\n",
    "You can find endpoints for Azure AI Search and Azure OpenAI in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You can find the project endpoint in the [Azure AI Foundry portal](https://ai.azure.com).\n",
    "   A hypothetical endpoint might look like this: `https://your-foundry-resource.services.ai.azure.com/api/projects/your-foundry-project`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d766f",
   "metadata": {},
   "source": [
    "[Checkpoint 3]\n",
    "![alt text](Image\\image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load Connections\n",
    "\n",
    "Load the environment variables to set up connections and object names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file (override=True ensures .env values take precedence)\n",
    "if not load_dotenv('../.env', override=True):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "# project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "project_endpoint = os.getenv(\"AZURE_AI_AGENT_ENDPOINT\")\n",
    "agent_model = os.getenv(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "print(f\"Project Endpoint: {project_endpoint}\")\n",
    "print(f\"Model Deployment Name: {agent_model}\")\n",
    "print(f\"Azure Search Endpoint: {endpoint}\")\n",
    "\n",
    "# Authentication setup using Azure's default credential chain\n",
    "# This will try managed identity, Azure CLI, Visual Studio, etc. in order\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "\n",
    "# Search index name - note the default differs from the constant above\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"12-earth-at-night\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Your Azure OpenAI service endpoint\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\")\n",
    "\n",
    "# Embedding model deployment settings for vector search\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "# Agent name for both Azure Search knowledge agent and AI Foundry agent\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"12-earth-search-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create search index on Azure AI Search\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# Create a comprehensive search index that supports both text and vector search\n",
    "# This index is designed for agentic retrieval workloads with semantic capabilities\n",
    "index = SearchIndex(\n",
    "    name=index_name,  # Use the index name from environment configuration\n",
    "    fields=[\n",
    "        # Primary key field - required for all Azure Search indexes\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        \n",
    "        # Text content field containing the actual document chunks\n",
    "        # This field is searchable but not filterable/sortable to optimize for text search\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        \n",
    "        # Vector embedding field for semantic similarity search\n",
    "        # - Collection(Edm.Single): Array of floating-point numbers representing the embedding\n",
    "        # - stored=False: Don't store the raw embeddings (saves space, still searchable)\n",
    "        # - vector_search_dimensions=3072: Dimension size for text-embedding-3-large model\n",
    "        # - vector_search_profile_name: Links to the vector search configuration below\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        \n",
    "        # Page number field for filtering and sorting results by document location\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    \n",
    "    # Vector search configuration using HNSW (Hierarchical Navigable Small World) algorithm\n",
    "    vector_search=VectorSearch(\n",
    "        # Vector search profiles define how vector fields are searched\n",
    "        profiles=[VectorSearchProfile(\n",
    "            name=\"hnsw_text_3_large\",  # Profile name referenced by vector fields\n",
    "            algorithm_configuration_name=\"alg\",  # Links to algorithm configuration\n",
    "            vectorizer_name=\"azure_openai_text_3_large\"  # Links to vectorizer configuration\n",
    "        )],\n",
    "        \n",
    "        # HNSW algorithm configuration for approximate nearest neighbor search\n",
    "        # HNSW provides good balance between search speed and accuracy\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        \n",
    "        # Vectorizer configuration - defines how text is converted to embeddings\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,  # Your Azure OpenAI endpoint\n",
    "                    deployment_name=azure_openai_embedding_deployment,  # Embedding model deployment\n",
    "                    model_name=azure_openai_embedding_model  # Embedding model name\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    # Semantic search configuration for intelligent ranking and understanding\n",
    "    # This is required for agentic retrieval workloads\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",  # Default semantic configuration\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                # Define which fields are prioritized for semantic understanding\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    # Content fields contain the main text content for semantic analysis\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")  # Use our text content field\n",
    "                    ]\n",
    "                    # Note: We could also define title_fields and keyword_fields for richer semantic understanding\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the search index client and deploy the index\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "# Create or update the index (idempotent operation)\n",
    "# If index exists, it will be updated with new schema; if not, it will be created\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dad23",
   "metadata": {},
   "source": [
    "[Checkpoint 4]\n",
    "![alt text](image/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This sample uses data from NASA's Earth at Night e-book. It's retrieved from the sample data GitHub repository and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "# URL pointing to pre-processed NASA Earth at Night e-book data\n",
    "# This data is already chunked and formatted for search indexing\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "\n",
    "# Download the sample documents from GitHub\n",
    "# The documents are already in the correct JSON format with fields matching our index schema\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "# Use SearchIndexingBufferedSender for efficient batch uploading\n",
    "# This class automatically handles batching, retries, and error handling\n",
    "# The 'with' statement ensures proper resource cleanup\n",
    "with SearchIndexingBufferedSender(\n",
    "    endpoint=endpoint,           # Azure Search service endpoint\n",
    "    index_name=index_name,      # Target index name\n",
    "    credential=credential       # Authentication credentials\n",
    ") as client:\n",
    "    # Upload all documents in batches\n",
    "    # The sender will automatically:\n",
    "    # - Split documents into optimal batch sizes\n",
    "    # - Generate embeddings using the configured vectorizer\n",
    "    # - Handle retries for failed uploads\n",
    "    # - Provide status updates\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a knowledge agent on Azure AI Search\n",
    "\n",
    "This steps creates a knowledge agent on Azure AI Search. This agent is a wrapper to a large language model, used for sending queries to an agentic retrieval pipeline. The maximum output size refers to the query response. Setting this value helps you control token usage and how many tokens are sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes for creating and managing Azure Search knowledge agents\n",
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# Create a knowledge agent - an AI-powered search orchestrator\n",
    "# The knowledge agent acts as an intelligent query planner that:\n",
    "# - Analyzes user queries for intent and complexity\n",
    "# - Decides what search strategies to use (keyword, vector, semantic, hybrid)\n",
    "# - Plans multi-step retrieval when needed\n",
    "# - Formats and ranks results for optimal relevance\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,  # Unique name for this knowledge agent\n",
    "    \n",
    "    # Configure the LLM models that power the agent's intelligence\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            # Connect to your Azure OpenAI GPT deployment\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,        # Your Azure OpenAI service endpoint\n",
    "                deployment_name=azure_openai_gpt_deployment, # GPT model deployment name\n",
    "                model_name=azure_openai_gpt_model           # GPT model name (e.g., gpt-4.1-mini)\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    # Define which search indexes this agent can query\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,          # The search index we created earlier\n",
    "            default_reranker_threshold=2.5  # Minimum relevance score for including results\n",
    "                                           # Higher values = more selective results\n",
    "                                           # Lower values = more comprehensive results\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    # Set limits to control resource usage and response quality\n",
    "    request_limits=KnowledgeAgentRequestLimits(\n",
    "        max_output_size=10000  # Maximum number of tokens in agent responses\n",
    "                              # Helps control costs and ensures responses fit in context windows\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the search index client and deploy the knowledge agent\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "# Create or update the knowledge agent (idempotent operation)\n",
    "# The agent becomes available immediately after creation\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Knowledge agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the knowledge agent was created successfully and is accessible\n",
    "# This is important because agent creation might succeed but the agent might not be immediately available\n",
    "try:\n",
    "    # Retrieve agent information from Azure Search\n",
    "    agent_info = index_client.get_agent(agent_name)\n",
    "    print(f\"Knowledge agent '{agent_info.name}' is available and working.\")\n",
    "except Exception as e:\n",
    "    print(f\"Knowledge agent '{agent_name}' is not available or not working: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an Azure AI Agent\n",
    "\n",
    "In the Azure AI Foundry, an agent is a smart micro-service that can do RAG. The purpose of this specific agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Azure AI Projects client for managing AI agents and workflows\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "# Create a client for the Azure AI Foundry project\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,  # Your AI Foundry project endpoint\n",
    "    credential=credential       # Use the same Azure credential for authentication\n",
    ")\n",
    "\n",
    "# List all existing agents in the project (for debugging/verification)\n",
    "list(project_client.agents.list_agents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55eda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system instructions for the AI agent\n",
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer using the format [ref_id].\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "# Key aspects of these instructions:\n",
    "# - Domain-specific: Focused on Earth at night topics\n",
    "# - Citation requirement: Must reference sources with [ref_id] format\n",
    "# - Honest about limitations: Says \"I don't know\" when information isn't available\n",
    "# - Structured responses: Expects JSON-formatted source data\n",
    "\n",
    "# Create the AI agent in Azure AI Foundry\n",
    "# This agent will orchestrate the entire RAG (Retrieval-Augmented Generation) pipeline\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=agent_model,      # The LLM model to use (e.g., gpt-4.1-mini)\n",
    "    name=agent_name,        # Agent name (same as knowledge agent for consistency)\n",
    "    instructions=instructions  # System prompt that defines agent behavior\n",
    ")\n",
    "# The agent will:\n",
    "# - Decide when to retrieve information from the search index\n",
    "# - Process user queries intelligently\n",
    "# - Coordinate with tools (like our agentic retrieval function)\n",
    "# - Format responses according to the instructions\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc4098",
   "metadata": {},
   "source": [
    "[Checkpoint 5]\n",
    "![alt text](Image/image5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the AI agent was created successfully in the Foundry project\n",
    "# This ensures the agent is ready to handle conversations and tool calls\n",
    "try:\n",
    "    # Retrieve agent information using the agent ID returned from creation\n",
    "    agent_info = project_client.agents.get_agent(agent.id)\n",
    "    print(f\"AI agent '{agent_info.name}' is available and working.\")\n",
    "except Exception as e:\n",
    "    print(f\"AI agent '{agent_name}' is not available or not working: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a051e",
   "metadata": {},
   "source": [
    "## Add an agentic retrieval tool to AI Agent\n",
    "\n",
    "An end-to-end pipeline needs an orchestration mechanism for coordinating calls to the retriever and agent. The pattern described in this notebook uses a [tool](https://learn.microsoft.com/azure/ai-services/agents/how-to/tools/function-calling) for this task. The tool calls the Azure AI Search knowledge retrieval client and the Azure AI agent, and it drives the conversations with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ee775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import FunctionTool, ToolSet, ListSortOrder\n",
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "# Create a knowledge retrieval client that connects to our Azure Search knowledge agent\n",
    "# This client handles the communication between the AI agent and the search index\n",
    "agent_client = KnowledgeAgentRetrievalClient(\n",
    "    endpoint=endpoint,          # Azure Search service endpoint\n",
    "    agent_name=agent_name,      # Name of the knowledge agent we created\n",
    "    credential=credential       # Authentication credentials\n",
    ")\n",
    "\n",
    "# Create a conversation thread for managing multi-turn conversations\n",
    "# Threads maintain context across multiple exchanges with the agent\n",
    "thread = project_client.agents.threads.create()\n",
    "\n",
    "# Dictionary to store retrieval results mapped to message IDs\n",
    "# This allows us to access detailed retrieval information later for analysis\n",
    "retrieval_results = {}\n",
    "\n",
    "def agentic_retrieval() -> str:\n",
    "    \"\"\"\n",
    "    Agentic retrieval function that searches NASA e-book data about Earth at night.\n",
    "    \n",
    "    This function serves as a \"tool\" that the AI agent can call when it needs to\n",
    "    retrieve information from the search index. The agent decides autonomously\n",
    "    when to use this tool based on the user's query.\n",
    "    \n",
    "    Returns:\n",
    "        str: JSON-formatted search results with reference IDs for citation\n",
    "    \n",
    "    The function performs these steps:\n",
    "    1. Gets recent conversation history for context\n",
    "    2. Sends the conversation to the knowledge agent for intelligent retrieval\n",
    "    3. Stores detailed retrieval results for later analysis\n",
    "    4. Returns the formatted response to the AI agent\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the last 5 messages from the conversation thread\n",
    "    # This provides context for the knowledge agent to understand the query intent\n",
    "    # DESCENDING order gets the most recent messages first\n",
    "    messages = project_client.agents.messages.list(\n",
    "        thread.id, \n",
    "        limit=5, \n",
    "        order=ListSortOrder.DESCENDING\n",
    "    )\n",
    "    \n",
    "    # Convert iterator to list and reverse to get chronological order\n",
    "    # (oldest message first, newest message last)\n",
    "    # This helps the knowledge agent understand conversation flow\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    \n",
    "    # Send the conversation context to the knowledge agent for intelligent retrieval\n",
    "    retrieval_result = agent_client.retrieve(\n",
    "        retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "            # Convert messages to the format expected by the knowledge agent\n",
    "            # Filter out system messages as they don't contain user queries\n",
    "            messages=[\n",
    "                KnowledgeAgentMessage(\n",
    "                    role=msg[\"role\"], \n",
    "                    content=[KnowledgeAgentMessageTextContent(text=msg.content[0].text)]\n",
    "                ) \n",
    "                for msg in messages \n",
    "                if msg[\"role\"] != \"system\"\n",
    "            ],\n",
    "            \n",
    "            # Configure the target index and search parameters\n",
    "            target_index_params=[\n",
    "                KnowledgeAgentIndexParams(\n",
    "                    index_name=index_name,      # Search in our Earth at night index\n",
    "                    reranker_threshold=2.5      # Minimum relevance score for results\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Store the detailed retrieval results for later analysis\n",
    "    # Associate with the most recent message in the conversation\n",
    "    last_message = messages[-1]\n",
    "    retrieval_results[last_message.id] = retrieval_result\n",
    "    \n",
    "    # Return the grounding response to the AI agent\n",
    "    # This contains the search results formatted for the agent to use in its response\n",
    "    return retrieval_result.response[0].content[0].text\n",
    "\n",
    "# Create a function tool from our agentic retrieval function\n",
    "# The AI agent can call this tool when it determines that information retrieval is needed\n",
    "# Reference: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling\n",
    "functions = FunctionTool({ agentic_retrieval })\n",
    "\n",
    "# Create a toolset and add our function tool\n",
    "# Toolsets group related tools that an agent can use\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "# Enable automatic function calling for the AI agent\n",
    "# This allows the agent to automatically decide when to call our agentic_retrieval function\n",
    "# The agent will analyze user queries and determine if search is needed\n",
    "project_client.agents.enable_auto_function_calls(toolset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babad0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the knowledge agent configuration and retrieval functionality\n",
    "# This cell performs a direct test of the retrieval system before full agent integration\n",
    "\n",
    "# Get detailed information about our knowledge agent\n",
    "agent_info = index_client.get_agent(agent_name)\n",
    "# Display which indexes the agent can search\n",
    "# This should show our \"earth-at-night\" index\n",
    "print(\"Agent target indexes:\", [ti.index_name for ti in agent_info.target_indexes])\n",
    "\n",
    "# Create a test message to verify the retrieval system works\n",
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the main topic of the NASA Earth at Night e-book?\"}\n",
    "]\n",
    "\n",
    "# Perform a direct retrieval test using the knowledge agent client\n",
    "# This bypasses the AI agent and tests the search functionality directly\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        # Convert test message to the format expected by the knowledge agent\n",
    "        messages=[\n",
    "            KnowledgeAgentMessage(\n",
    "                role=msg[\"role\"], \n",
    "                content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]\n",
    "            ) \n",
    "            for msg in test_messages\n",
    "        ],\n",
    "        \n",
    "        # Configure search parameters for the test\n",
    "        target_index_params=[\n",
    "            KnowledgeAgentIndexParams(\n",
    "                index_name=index_name,      # Search our Earth at night index\n",
    "                reranker_threshold=2.5      # Use same threshold as in production\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the raw retrieval response\n",
    "# This shows what the knowledge agent found and how it formatted the results\n",
    "# The response should contain relevant information about the NASA e-book\n",
    "print(\"Retrieval response:\", retrieval_result.response[0].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b293e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate where the agentic_retrieval function is stored\n",
    "print(\"=== agentic_retrieval Function Storage Information ===\")\n",
    "\n",
    "# 1. The function exists in the current Python namespace (memory)\n",
    "print(f\"Function name: {agentic_retrieval.__name__}\")\n",
    "print(f\"Function type: {type(agentic_retrieval)}\")\n",
    "print(f\"Function location in memory: {id(agentic_retrieval)}\")\n",
    "\n",
    "# 2. Check if it's part of the FunctionTool\n",
    "print(f\"\\nFunctionTool contains: {functions}\")\n",
    "print(f\"FunctionTool type: {type(functions)}\")\n",
    "\n",
    "# 3. Check if it's registered with the agent's toolset\n",
    "print(f\"\\nToolset object: {toolset}\")\n",
    "print(\"Toolset type:\", type(toolset))\n",
    "\n",
    "# 4. The function's docstring and signature\n",
    "print(f\"\\nFunction signature: {agentic_retrieval.__doc__}\")\n",
    "\n",
    "# 5. Show where it's NOT stored (it's ephemeral)\n",
    "print(\"\\n=== What this function is NOT stored in: ===\")\n",
    "print(\"❌ Not in a database\")\n",
    "print(\"❌ Not in a file on disk\") \n",
    "print(\"❌ Not persisted in Azure\")\n",
    "print(\"❌ Not saved between notebook sessions\")\n",
    "print(\"✅ Only exists in current Python runtime memory\")\n",
    "print(\"✅ Must be redefined if kernel restarts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5b621",
   "metadata": {},
   "source": [
    "## Start a chat with the agent\n",
    "\n",
    "During the chat, you use the standard Azure AI agent tool calling APIs.  We send the message with questions, and the agent decides when to retrieve knowledge from your search index using agentic retrieval.\n",
    "\n",
    "The remaining cells take a closer look at output and show how to add another turn to the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes for controlling agent tool selection\n",
    "from azure.ai.agents.models import AgentsNamedToolChoice, AgentsNamedToolChoiceType, FunctionName\n",
    "\n",
    "# Create a user message with complex questions about Earth at night phenomena\n",
    "# These questions test the agent's ability to:\n",
    "# - Handle multi-part queries\n",
    "# - Understand scientific concepts\n",
    "# - Find specific information in the knowledge base\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Execute the agent run with forced tool usage\n",
    "# We explicitly force the agent to use our agentic_retrieval tool to ensure\n",
    "# it searches for information rather than relying only on its training data\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,        # Use our conversation thread\n",
    "    agent_id=agent.id,          # Use our created agent\n",
    "    \n",
    "    # Force the agent to use our agentic_retrieval function\n",
    "    # This ensures the agent will search the index for information\n",
    "    tool_choice=AgentsNamedToolChoice(\n",
    "        type=AgentsNamedToolChoiceType.FUNCTION, \n",
    "        function=FunctionName(name=\"agentic_retrieval\")\n",
    "    ),\n",
    "    \n",
    "    toolset=toolset  # Provide access to our retrieval tool\n",
    ")\n",
    "\n",
    "# Check if the agent run completed successfully\n",
    "# If it failed, we want to know why (could be model issues, tool problems, etc.)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Get the agent's response to our question\n",
    "# The agent should have used our retrieval tool to find relevant information\n",
    "# and formatted it according to our instructions (with citation references)\n",
    "output = project_client.agents.messages.get_last_message_text_by_role(\n",
    "    thread_id=thread.id, \n",
    "    role=\"assistant\"\n",
    ").text.value\n",
    "\n",
    "# Display the agent's response with improved formatting\n",
    "# Replace periods with newlines for better readability of the detailed response\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88be35",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n",
    "\n",
    "Each retrieval response from Azure AI Search includes the unified string (grounding data from search search results), the query plan, and  reference data showing which chunks of source document contributed content to the unified string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import JSON for pretty-printing the retrieval analysis\n",
    "import json\n",
    "\n",
    "# Retrieve the detailed retrieval results for the message we just processed\n",
    "# This gives us insight into what the knowledge agent actually did behind the scenes\n",
    "retrieval_result = retrieval_results.get(message.id)\n",
    "\n",
    "# Ensure we have retrieval results for this message\n",
    "# This could fail if the agent didn't use our retrieval tool or if there was an error\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "# Display the retrieval activity log\n",
    "# This shows the step-by-step process the knowledge agent went through:\n",
    "# - Query analysis and understanding\n",
    "# - Search strategy selection (keyword, vector, semantic, hybrid)\n",
    "# - Query reformulation and expansion\n",
    "# - Result ranking and filtering\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "\n",
    "# Display the retrieval results and references\n",
    "# This shows:\n",
    "# - Which documents were found and considered relevant\n",
    "# - Relevance scores for each result\n",
    "# - The specific chunks of text that contributed to the response\n",
    "# - Reference IDs that should appear in the agent's response citations\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bfb9f",
   "metadata": {},
   "source": [
    "## Continue the conversation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9478191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation with a new question\n",
    "# This demonstrates multi-turn conversation capabilities and context maintenance\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,  # Use the same thread to maintain conversation context\n",
    "    role=\"user\",\n",
    "    content=\"How do I find lava at night? Use the retrieval tool to answer this question.\"\n",
    ")\n",
    "# Note: This question explicitly asks the agent to use the retrieval tool\n",
    "# This tests whether the agent can find information about thermal detection\n",
    "# and volcanic activity observation from space\n",
    "\n",
    "# Execute another agent run with the same configuration\n",
    "# The agent now has the context of the previous conversation\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,        # Same conversation thread for context\n",
    "    agent_id=agent.id,          # Same agent instance\n",
    "    \n",
    "    # Again force the use of our retrieval tool\n",
    "    # This ensures consistent behavior for demonstration purposes\n",
    "    tool_choice=AgentsNamedToolChoice(\n",
    "        type=AgentsNamedToolChoiceType.FUNCTION, \n",
    "        function=FunctionName(name=\"agentic_retrieval\")\n",
    "    ),\n",
    "    \n",
    "    toolset=toolset  # Same toolset with our retrieval function\n",
    ")\n",
    "\n",
    "# Check for execution errors\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Get the agent's response to the lava detection question\n",
    "# The response should incorporate both the new query and any relevant context\n",
    "# from the previous conversation if applicable\n",
    "output = project_client.agents.messages.get_last_message_text_by_role(\n",
    "    thread_id=thread.id, \n",
    "    role=\"assistant\"\n",
    ").text.value\n",
    "\n",
    "# Display the response with formatting for better readability\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366ed37",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the retrieval results for the second question (about finding lava at night)\n",
    "# This allows us to compare how the knowledge agent handled different types of queries\n",
    "\n",
    "# Get the retrieval results for the lava detection question\n",
    "retrieval_result = retrieval_results.get(message.id)\n",
    "\n",
    "# Verify we have results for this message\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "# Display the retrieval activity for the lava detection query\n",
    "# Compare this with the previous query to see how the agent:\n",
    "# - Adapted its search strategy for a different topic\n",
    "# - Used different keywords or semantic understanding\n",
    "# - Potentially found different types of content\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "\n",
    "# Display the specific results and references found for lava detection\n",
    "# This might include information about:\n",
    "# - Thermal imaging techniques\n",
    "# - Infrared detection methods\n",
    "# - Volcanic monitoring from satellite imagery\n",
    "# - Temperature signatures of geological activity\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04661708",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need the resources, be sure to delete them from your Azure subscription.  You can also delete individual objects to start over.\n",
    "\n",
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_agent(agent_name)\n",
    "print(f\"Knowledge agent '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2e274",
   "metadata": {},
   "source": [
    "### Delete the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1baead",
   "metadata": {},
   "source": [
    "### Delete the AI agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the AI agent from Azure AI Foundry to clean up resources\n",
    "\n",
    "# Use the project_client to delete the agent by its ID\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(f\"AI agent '{agent.name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
